# Evaluation Report: Singlish-to-English NLP Translator

**Project:** Singlish-to-English NLP Cascade Translator  
**Course:** NLP Machine Translation Module  
**Date:** [TO BE FILLED]  
**Team:** Student 1, Student 2, Student 3

---

## 1. Executive Summary

[Brief overview of the project and key findings]

---

## 2. Automatic Evaluation Results

### BLEU Score

- **Overall BLEU Score:** [TO BE FILLED]
- **Interpretation:** [Explain what this score means]

### Per-Module Performance

- **Module 1 (FST Transliteration):** [Accuracy/Error rate]
- **Module 2 (RBMT Translation):** [Accuracy/Error rate]
- **Module 3 (Post-Processing):** [Quality improvements]

---

## 3. Human Evaluation Results

### Adequacy Scores (1-5 Scale)

- **Scale Definition:**
  - 5 = All meaning preserved
  - 4 = Most meaning preserved
  - 3 = Much meaning preserved
  - 2 = Little meaning preserved
  - 1 = No meaning preserved

- **Average Adequacy Score:** [TO BE FILLED]

### Fluency Scores (1-5 Scale)

- **Scale Definition:**
  - 5 = Perfect fluent English
  - 4 = Good English, minor errors
  - 3 = Non-native English, understandable
  - 2 = Disfluent, hard to understand
  - 1 = Incomprehensible

- **Average Fluency Score:** [TO BE FILLED]

### Inter-Rater Agreement

- **Number of Raters:** [TO BE FILLED]
- **Agreement Level:** [TO BE FILLED]

---

## 4. Error Analysis

### Module 1 Errors (FST Transliteration)

[List common errors and examples]
- Error type 1: [Description]
- Error type 2: [Description]

### Module 2 Errors (RBMT Translation)

[List common errors and examples]
- Error type 1: [Description]
- Error type 2: [Description]

### Module 3 Errors (Post-Processing)

[List common errors and examples]
- Error type 1: [Description]
- Error type 2: [Description]

---

## 5. Example Translations

### Successful Translations

| Singlish Input | System Output | Reference | Notes |
|---------------|---------------|-----------|-------|
| [example] | [output] | [reference] | [notes] |

### Failed Translations

| Singlish Input | System Output | Reference | Error Type |
|---------------|---------------|-----------|------------|
| [example] | [output] | [reference] | [error] |

---

## 6. Discussion

### Strengths

[What worked well in the system]

### Limitations

[What didn't work well]

### Lessons Learned

[Key takeaways from the project]

---

## 7. Future Work

[Suggestions for improving the system]

---

## 8. Conclusion

[Final summary of the project outcomes]

---

## Appendices

### Appendix A: Corpus Statistics

- **Total Sentences:** [TO BE FILLED]
- **Average Sentence Length:** [TO BE FILLED]
- **Vocabulary Size:** [TO BE FILLED]

### Appendix B: System Configuration

- **Python Version:** [TO BE FILLED]
- **pynini Version:** [TO BE FILLED]
- **nltk Version:** [TO BE FILLED]

